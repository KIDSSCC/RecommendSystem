{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cc02dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "85d0378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    加载文件，从data/train.txt中加载原始训练数据，统计原始训练数据中的相关信息，进行打印输出\n",
    "    形成字典sparse_matrix，sparse_matrix的键为用户编号，sparse_matrix的值为另一个字典rate_of_curruser\n",
    "    字典rate_of_curruser的键为物品的编号，值为当前用户对该物品的评分。\n",
    "    :return:sparse_matrix\n",
    "    \"\"\"\n",
    "    start_time=time.time()\n",
    "    train_path='data/train.txt'\n",
    "    users=[]\n",
    "    items=[]\n",
    "    rates=[]\n",
    "    with open(train_path,'r') as file:\n",
    "        top_line=file.readline()\n",
    "        sparse_matrix=dict()\n",
    "        while top_line:\n",
    "            user,nums=top_line.split('|')\n",
    "            user=int(user)\n",
    "            nums=int(nums)\n",
    "            users.append(user)\n",
    "            rate_of_curruser=dict()\n",
    "            for i in range(nums):\n",
    "                rate_line=file.readline()\n",
    "                item,rate=rate_line.split()\n",
    "                item=int(item)\n",
    "                rate=int(rate)\n",
    "                items.append(item)\n",
    "                rates.append(rate)\n",
    "                rate_of_curruser[item]=rate\n",
    "            sparse_matrix[user]=rate_of_curruser\n",
    "            top_line=file.readline()\n",
    "\n",
    "        # 数据统计输出\n",
    "        set_users = sorted(list(set(users)))\n",
    "        set_items = sorted(list(set(items)))\n",
    "        print('关于用户:')\n",
    "        print('实际的用户数量:{}'.format(len(set_users)))\n",
    "        print('用户的编号范围: {} 至 {}'.format(set_users[0],set_users[-1]))\n",
    "        print('关于物品:')\n",
    "        print('实际的物品数量:{}'.format(len(set_items)))\n",
    "        print('物品的编号范围: {} 至 {}'.format(set_items[0], set_items[-1]))\n",
    "        print('矩阵中的空闲率:{}'.format(1-len(items)/(len(set_items)*len(set_users))))\n",
    "        end_time=time.time()\n",
    "        print('加载原始数据，用时{}秒'.format(end_time-start_time))\n",
    "        return set_users,set_items,sparse_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c41f7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_spilt(matrix,sample_rate=0.2):\n",
    "    \"\"\"\n",
    "\n",
    "    :param matrix:原始的训练数据字典\n",
    "    :param sample_rate:测试集划分比率，默认为20%\n",
    "    :return:训练集字典和测试集字典\n",
    "    \"\"\"\n",
    "    start_time=time.time()\n",
    "    train_data=dict()\n",
    "    test_data=dict()\n",
    "    for user,rate_dict in matrix.items():\n",
    "        sample_num=int(len(rate_dict)*sample_rate)\n",
    "\n",
    "        test_keys=random.sample(list(rate_dict),sample_num)\n",
    "        tmp_test_data={key:rate_dict[key] for key in test_keys}\n",
    "        tmp_train_data={key:rate_dict[key] for key in rate_dict if key not in test_keys}\n",
    "        train_data[user]=tmp_train_data\n",
    "        test_data[user]=tmp_test_data\n",
    "    end_time=time.time()\n",
    "    print('训练集数据划分，用时{}秒'.format(end_time-start_time))\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a88a8ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attribute(bi):\n",
    "    start=time.time()\n",
    "    file_path='data/itemAttribute.txt'\n",
    "    attr_dict=dict()\n",
    "    with open(file_path,'r') as f:\n",
    "        line=f.readline()\n",
    "        debug=10000\n",
    "        while line:\n",
    "            item,att1,att2=line.split('|')\n",
    "            if int(item)>debug:\n",
    "                debug+=10000\n",
    "                print(item)\n",
    "            if 'None' in att1:\n",
    "                att1=-1\n",
    "            if 'None' in att2:\n",
    "                att2=-1\n",
    "            if int(item) in bi:\n",
    "                attr_dict[int(item)]=[int(att1),int(att2)]\n",
    "            line=f.readline()\n",
    "    index2no=dict()\n",
    "    no2index=dict()\n",
    "    attr_array=np.zeros((len(attr_dict),2))\n",
    "    index=0\n",
    "    for item,attr in attr_dict.items():\n",
    "        index2no[index]=item\n",
    "        no2index[item]=index\n",
    "        attr_array[index] = attr\n",
    "        index+=1\n",
    "\n",
    "    end=time.time()\n",
    "    print('加载属性，用时{} s'.format(end-start))\n",
    "    return index2no,no2index,attr_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d935da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbour(item_no,no2index,index2no,attr_array,kdtree,k):\n",
    "    if item_no not in no2index:\n",
    "        return []\n",
    "    else:\n",
    "        index=no2index[item_no]\n",
    "        dist,ind=kdtree.query(attr_array[index],k)\n",
    "        item_list=[index2no[i] for i in ind ]\n",
    "        return item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c977798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbour_item(bi):\n",
    "    res=dict()\n",
    "    index2no,no2index,attr_array=load_attribute(bi)\n",
    "    kdtree=KDTree(attr_array)\n",
    "    for item in bi.keys():\n",
    "        # 对于当前的每一个物品\n",
    "        if item not in no2index:\n",
    "            res[item]=[]\n",
    "        else:\n",
    "            index = no2index[item]\n",
    "            dist, ind = kdtree.query(attr_array[index], 5)\n",
    "            item_list = [index2no[i] for i in ind]\n",
    "            res[item]=item_list\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ed21a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fit_model:\n",
    "\n",
    "    def __init__(self,mean,bias_u,bias_i,pu,qi):\n",
    "        self.mean=mean\n",
    "        self.bias_u=bias_u\n",
    "        self.bias_i=bias_i\n",
    "        self.pu=pu\n",
    "        self.qi=qi\n",
    "        self.neighbour=neighbour_item(bias_i)\n",
    "        print(self.neighbour)\n",
    "\n",
    "    def predict_score(self,user_no,item_no):\n",
    "        basic=self.pu[user_no]@self.qi[item_no]\n",
    "        return basic+self.mean+self.bias_u[user_no]+self.bias_i[item_no]\n",
    "\n",
    "    def pred_attribute(self,user_no,item_no):\n",
    "        basic = self.pu[user_no] @ self.qi[item_no]+self.bias_i[item_no]\n",
    "        item_list=self.neighbour[item_no]\n",
    "        for item in item_list:\n",
    "            basic+=self.pu[user_no] @ self.qi[item]+self.bias_i[item]\n",
    "        return basic/(len(item_list)+1)+self.bias_u[user_no]+self.mean\n",
    "\n",
    "    def gradient_desc(self,user_no,item_no,error,lr,lamb):\n",
    "        self.bias_u[user_no] += lr * (error - lamb * self.bias_u[user_no])\n",
    "        self.bias_i[item_no] += lr * (error - lamb * self.bias_i[item_no])\n",
    "        old_pu=self.pu[user_no]\n",
    "        old_qi=self.qi[item_no]\n",
    "        self.pu[user_no] += lr * (error * old_qi - lamb * old_pu)\n",
    "        self.qi[item_no] += lr * (error * old_pu - lamb * old_qi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c87bcb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_of_train(train):\n",
    "    sum_rate=0\n",
    "    count=0\n",
    "    for user,items in train.items():\n",
    "        for item_no in items.keys():\n",
    "            sum_rate+=items[item_no]\n",
    "            count+=1\n",
    "    return sum_rate/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "17ce19f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funk_svd_train(train,test,set_users,set_items,n_epoch,lr,k,lamb):\n",
    "    mean = get_mean_of_train(train)\n",
    "    bias_u = dict()\n",
    "    bias_i = dict()\n",
    "    pu = dict()\n",
    "    qi = dict()\n",
    "    for user_no in set_users:\n",
    "        bias_u[user_no]=0\n",
    "        pu[user_no]=np.random.normal(0, .1, k)\n",
    "    for item_no in set_items:\n",
    "        bias_i[item_no]=0\n",
    "        qi[item_no]=np.random.normal(0, .1, k)\n",
    "\n",
    "    model=fit_model(mean,bias_u,bias_i,pu,qi)\n",
    "    for epoch in range(n_epoch):\n",
    "        for user_no,items in train.items():\n",
    "            for item_no,real_rate in items.items():\n",
    "                predict_rate=model.pred_attribute(user_no,item_no)\n",
    "                error=real_rate-predict_rate\n",
    "                # 梯度下降\n",
    "                model.gradient_desc(user_no,item_no,error,lr,lamb)\n",
    "            if user_no % 2000 == 0:\n",
    "                print('user progress:[{}/{}]'.format(user_no, len(train)))\n",
    "        # 完成一轮迭代\n",
    "        rmse_in_train=funk_svd_eval(train,model)\n",
    "        rmse_in_test=funk_svd_eval(test,model)\n",
    "        print('epoch:[{}/{}],RMSE in train is :{} , and RMSE in test is {}'.format(epoch,n_epoch,rmse_in_train,rmse_in_test))\n",
    "        pickle_path='models/fit_model'+str(epoch)+'.pkl'\n",
    "        with open(pickle_path,'wb') as f:\n",
    "            pickle.dump(fit_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dba88929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funk_svd_eval(test,fit_model):\n",
    "    sum_error=0\n",
    "    count=0\n",
    "    for user_no,items in test.items():\n",
    "        for item_no,real_rate in items.items():\n",
    "            predict_rate=fit_model.predict_score(user_no,item_no)\n",
    "            sum_error+=(real_rate-predict_rate)**2\n",
    "            count+=1\n",
    "\n",
    "    return np.sqrt(sum_error/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d4686cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关于用户:\n",
      "实际的用户数量:19835\n",
      "用户的编号范围: 0 至 19834\n",
      "关于物品:\n",
      "实际的物品数量:455705\n",
      "物品的编号范围: 0 至 624960\n",
      "矩阵中的空闲率:0.9994466691522359\n",
      "加载原始数据，用时6.222656965255737秒\n",
      "训练集数据划分，用时36.37710094451904秒\n"
     ]
    }
   ],
   "source": [
    "set_users,set_items,sparse_matrix=load_data()\n",
    "train,test=train_test_spilt(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "518e31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=30\n",
    "mean = get_mean_of_train(train)\n",
    "bias_u = dict()\n",
    "bias_i = dict()\n",
    "pu = dict()\n",
    "qi = dict()\n",
    "for user_no in set_users:\n",
    "    bias_u[user_no]=0\n",
    "    pu[user_no]=np.random.normal(0, .1, k)\n",
    "for item_no in set_items:\n",
    "    bias_i[item_no]=0\n",
    "    qi[item_no]=np.random.normal(0, .1, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "772b63fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001\n",
      "20001\n",
      "30001\n",
      "40001\n",
      "50001\n",
      "60001\n",
      "70002\n",
      "80003\n",
      "90001\n",
      "100001\n",
      "110001\n",
      "120001\n",
      "130002\n",
      "140001\n",
      "150002\n",
      "160001\n",
      "170001\n",
      "180001\n",
      "190001\n",
      "200001\n",
      "210001\n",
      "220001\n",
      "230001\n",
      "240001\n",
      "250001\n",
      "260002\n",
      "270001\n",
      "280001\n",
      "290001\n",
      "300002\n",
      "310001\n",
      "320001\n",
      "330001\n",
      "340001\n",
      "350001\n",
      "360001\n",
      "370001\n",
      "380001\n",
      "390001\n",
      "400001\n",
      "410001\n",
      "420001\n",
      "430001\n",
      "440001\n",
      "450001\n",
      "460001\n",
      "470001\n",
      "480001\n",
      "490001\n",
      "500001\n",
      "510001\n",
      "520001\n",
      "530002\n",
      "540001\n",
      "550002\n",
      "560001\n",
      "570002\n",
      "580002\n",
      "590002\n",
      "600003\n",
      "610001\n",
      "620002\n",
      "加载属性，用时2.3667335510253906 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=fit_model(mean,bias_u,bias_i,pu,qi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "76095d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507172\n",
      "0\n",
      "624960\n"
     ]
    }
   ],
   "source": [
    "file_path='data/itemAttribute.txt'\n",
    "attr_dict=dict()\n",
    "with open(file_path,'r') as f:\n",
    "    line=f.readline()\n",
    "    while line:\n",
    "        item,att1,att2=line.split('|')\n",
    "        if 'None' in att1:\n",
    "            att1=-1\n",
    "        if 'None' in att2:\n",
    "            att2=-1\n",
    "        attr_dict[int(item)]=[int(att1),int(att2)]\n",
    "        line=f.readline()\n",
    "res=sorted(list(set(attr_dict.keys())))\n",
    "print(len(res))\n",
    "print(res[0])\n",
    "print(res[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cddc69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
