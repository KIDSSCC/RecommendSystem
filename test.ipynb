{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "867be3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da72026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    加载文件，从data/train.txt中加载原始训练数据，统计原始训练数据中的相关信息，进行打印输出\n",
    "    形成字典sparse_matrix，sparse_matrix的键为用户编号，sparse_matrix的值为另一个字典rate_of_curruser\n",
    "    字典rate_of_curruser的键为物品的编号，值为当前用户对该物品的评分。\n",
    "    :return:sparse_matrix\n",
    "    \"\"\"\n",
    "    start_time=time.time()\n",
    "    train_path='data/train.txt'\n",
    "    users=[]\n",
    "    items=[]\n",
    "    rates=[]\n",
    "    with open(train_path,'r') as file:\n",
    "        top_line=file.readline()\n",
    "        sparse_matrix=dict()\n",
    "        while top_line:\n",
    "            user,nums=top_line.split('|')\n",
    "            user=int(user)\n",
    "            nums=int(nums)\n",
    "            users.append(user)\n",
    "            rate_of_curruser=dict()\n",
    "            for i in range(nums):\n",
    "                rate_line=file.readline()\n",
    "                item,rate=rate_line.split()\n",
    "                item=int(item)\n",
    "                rate=int(rate)\n",
    "                items.append(item)\n",
    "                rates.append(rate)\n",
    "                rate_of_curruser[item]=rate\n",
    "            sparse_matrix[user]=rate_of_curruser\n",
    "            top_line=file.readline()\n",
    "\n",
    "        # 数据统计输出\n",
    "        set_users = sorted(list(set(users)))\n",
    "        set_items = sorted(list(set(items)))\n",
    "        print('关于用户:')\n",
    "        print('实际的用户数量:{}'.format(len(set_users)))\n",
    "        print('用户的编号范围: {} 至 {}'.format(set_users[0],set_users[-1]))\n",
    "        print('关于物品:')\n",
    "        print('实际的物品数量:{}'.format(len(set_items)))\n",
    "        print('物品的编号范围: {} 至 {}'.format(set_items[0], set_items[-1]))\n",
    "        print('矩阵中的空闲率:{}'.format(1-len(items)/(len(set_items)*len(set_users))))\n",
    "        end_time=time.time()\n",
    "        print('加载原始数据，用时{}秒'.format(end_time-start_time))\n",
    "        return set_users,set_items,sparse_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "619f6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_spilt(matrix,sample_rate=0.2):\n",
    "    \"\"\"\n",
    "\n",
    "    :param matrix:原始的训练数据字典\n",
    "    :param sample_rate:测试集划分比率，默认为20%\n",
    "    :return:训练集字典和测试集字典\n",
    "    \"\"\"\n",
    "    start_time=time.time()\n",
    "    train_data=dict()\n",
    "    test_data=dict()\n",
    "    for user,rate_dict in matrix.items():\n",
    "        sample_num=int(len(rate_dict)*sample_rate)\n",
    "\n",
    "        test_keys=random.sample(list(rate_dict),sample_num)\n",
    "        tmp_test_data={key:rate_dict[key] for key in test_keys}\n",
    "        tmp_train_data={key:rate_dict[key] for key in rate_dict if key not in test_keys}\n",
    "        train_data[user]=tmp_train_data\n",
    "        test_data[user]=tmp_test_data\n",
    "    end_time=time.time()\n",
    "    print('训练集数据划分，用时{}秒'.format(end_time-start_time))\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d3837f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attribute(set_items):\n",
    "    print(len(set_items))\n",
    "    start=time.time()\n",
    "    file_path='data/itemAttribute.txt'\n",
    "    attr_dict=dict()\n",
    "    with open(file_path,'r') as f:\n",
    "        line=f.readline()\n",
    "        while line:\n",
    "            item,att1,att2=line.split('|')\n",
    "            if 'None' in att1:\n",
    "                att1=-1\n",
    "            if 'None' in att2:\n",
    "                att2=-1\n",
    "            if int(item) in set_items:\n",
    "                attr_dict[int(item)]=[int(att1),int(att2)]\n",
    "            line=f.readline()\n",
    "    index2no=dict()\n",
    "    no2index=dict()\n",
    "    attr_array=np.zeros((len(attr_dict),2))\n",
    "    index=0\n",
    "    for item,attr in attr_dict.items():\n",
    "        index2no[index]=item\n",
    "        no2index[item]=index\n",
    "        attr_array[index] = attr\n",
    "        index+=1\n",
    "\n",
    "    end=time.time()\n",
    "    print('加载属性，用时{} s'.format(end-start))\n",
    "    return index2no,no2index,attr_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c34e9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_neighbour(item_no,no2index,index2no,attr_array,kdtree,k):\n",
    "    if item_no not in no2index:\n",
    "        return []\n",
    "    else:\n",
    "        index=no2index[item_no]\n",
    "        dist,ind=kdtree.query(attr_array[index],k)\n",
    "        item_list=[index2no[i] for i in ind ]\n",
    "        return item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c036352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fit_model:\n",
    "\n",
    "    def __init__(self,mean,bias_u,bias_i,pu,qi,set_items):\n",
    "        self.mean=mean\n",
    "        self.bias_u=bias_u\n",
    "        self.bias_i=bias_i\n",
    "        self.pu=pu\n",
    "        self.qi=qi\n",
    "        self.index2no, self.no2index, self.attr_array=load_attribute(set_items)\n",
    "        self.kdtree=KDTree(self.attr_array)\n",
    "\n",
    "    def predict_score(self,user_no,item_no):\n",
    "        basic=self.pu[user_no]@self.qi[item_no]\n",
    "        return basic+self.mean+self.bias_u[user_no]+self.bias_i[item_no]\n",
    "\n",
    "    def pred_attribute(self,user_no,item_no):\n",
    "        basic = self.pu[user_no] @ self.qi[item_no]+self.bias_i[item_no]\n",
    "        item_list=k_neighbour(item_no,self.no2index,self.index2no,self.attr_array,self.kdtree,5)\n",
    "        for item in item_list:\n",
    "            basic+=self.pu[user_no] @ self.qi[item]+self.bias_i[item]\n",
    "        return basic/(len(item_list)+1)+self.bias_u[user_no]+self.mean\n",
    "\n",
    "    def gradient_desc(self,user_no,item_no,error,lr,lamb):\n",
    "        self.bias_u[user_no] += lr * (error - lamb * self.bias_u[user_no])\n",
    "        self.bias_i[item_no] += lr * (error - lamb * self.bias_i[item_no])\n",
    "        old_pu=self.pu[user_no]\n",
    "        old_qi=self.qi[item_no]\n",
    "        self.pu[user_no] += lr * (error * old_qi - lamb * old_pu)\n",
    "        self.qi[item_no] += lr * (error * old_pu - lamb * old_qi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5fd4df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_of_train(train):\n",
    "    sum_rate=0\n",
    "    count=0\n",
    "    for user,items in train.items():\n",
    "        for item_no in items.keys():\n",
    "            sum_rate+=items[item_no]\n",
    "            count+=1\n",
    "    return sum_rate/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dda89b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funk_svd_train(train,test,set_users,set_items,n_epoch,lr,k,lamb):\n",
    "    print('here')\n",
    "    mean = get_mean_of_train(train)\n",
    "    bias_u = dict()\n",
    "    bias_i = dict()\n",
    "    pu = dict()\n",
    "    qi = dict()\n",
    "    for user_no in set_users:\n",
    "        bias_u[user_no]=0\n",
    "        pu[user_no]=np.random.normal(0, .1, k)\n",
    "    for item_no in set_items:\n",
    "        bias_i[item_no]=0\n",
    "        qi[item_no]=np.random.normal(0, .1, k)\n",
    "    print('here')\n",
    "    model=fit_model(mean,bias_u,bias_i,pu,qi,set_items)\n",
    "    print('create model')\n",
    "    for epoch in range(n_epoch):\n",
    "        for user_no,items in train.items():\n",
    "            for item_no,real_rate in items.items():\n",
    "                predict_rate=model.pred_attribute(user_no,item_no)\n",
    "                error=real_rate-predict_rate\n",
    "                # 梯度下降\n",
    "                model.gradient_desc(user_no,item_no,error,lr,lamb)\n",
    "            if user_no % 2000 == 0:\n",
    "                print('user progress:[{}/{}]'.format(user_no, len(train)))\n",
    "        # 完成一轮迭代\n",
    "        rmse_in_train=funk_svd_eval(train,model)\n",
    "        rmse_in_test=funk_svd_eval(test,model)\n",
    "        print('epoch:[{}/{}],RMSE in train is :{} , and RMSE in test is {}'.format(epoch,n_epoch,rmse_in_train,rmse_in_test))\n",
    "        pickle_path='models/fit_model'+str(epoch)+'.pkl'\n",
    "        with open(pickle_path,'wb') as f:\n",
    "            pickle.dump(fit_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "522de00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funk_svd_eval(test,fit_model):\n",
    "    sum_error=0\n",
    "    count=0\n",
    "    for user_no,items in test.items():\n",
    "        for item_no,real_rate in items.items():\n",
    "            predict_rate=fit_model.predict_score(user_no,item_no)\n",
    "            sum_error+=(real_rate-predict_rate)**2\n",
    "            count+=1\n",
    "\n",
    "    return np.sqrt(sum_error/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41d82c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关于用户:\n",
      "实际的用户数量:19835\n",
      "用户的编号范围: 0 至 19834\n",
      "关于物品:\n",
      "实际的物品数量:455705\n",
      "物品的编号范围: 0 至 624960\n",
      "矩阵中的空闲率:0.9994466691522359\n",
      "加载原始数据，用时6.021545886993408秒\n",
      "训练集数据划分，用时36.1547908782959秒\n"
     ]
    }
   ],
   "source": [
    "set_users,set_items,sparse_matrix=load_data()\n",
    "train,test=train_test_spilt(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f4f0b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "455705\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfunk_svd_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43mset_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43mset_items\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[73], line 15\u001b[0m, in \u001b[0;36mfunk_svd_train\u001b[1;34m(train, test, set_users, set_items, n_epoch, lr, k, lamb)\u001b[0m\n\u001b[0;32m     13\u001b[0m     qi[item_no]\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m.1\u001b[39m, k)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhere\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbias_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbias_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43mqi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mset_items\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epoch):\n",
      "Cell \u001b[1;32mIn[71], line 9\u001b[0m, in \u001b[0;36mfit_model.__init__\u001b[1;34m(self, mean, bias_u, bias_i, pu, qi, set_items)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpu\u001b[38;5;241m=\u001b[39mpu\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqi\u001b[38;5;241m=\u001b[39mqi\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex2no, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno2index, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattr_array\u001b[38;5;241m=\u001b[39m\u001b[43mload_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_items\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkdtree\u001b[38;5;241m=\u001b[39mKDTree(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattr_array)\n",
      "Cell \u001b[1;32mIn[69], line 16\u001b[0m, in \u001b[0;36mload_attribute\u001b[1;34m(set_items)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(item) \u001b[38;5;129;01min\u001b[39;00m set_items:\n\u001b[0;32m     15\u001b[0m             attr_dict[\u001b[38;5;28mint\u001b[39m(item)]\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mint\u001b[39m(att1),\u001b[38;5;28mint\u001b[39m(att2)]\n\u001b[1;32m---> 16\u001b[0m         line\u001b[38;5;241m=\u001b[39m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m index2no\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m     18\u001b[0m no2index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "funk_svd_train(train,test,set_users,set_items,50,5e-4,30,0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1655a60a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
